{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b0e2a55",
   "metadata": {},
   "source": [
    "## Project Report -- Week 5 Kaggle Getting Started Code Competition: Iâ€™m Something of a Painter Myself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c638124",
   "metadata": {},
   "source": [
    "Project Repository: https://github.com/albert-kepner/Week5_DL_CycleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfa51d4",
   "metadata": {},
   "source": [
    "### Problem Description and Exploratory Data Analysis\n",
    "\n",
    "Please see this link: https://github.com/albert-kepner/Week5_DL_CycleGAN/blob/master/AK_ExploratoryDataAnalysis.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ed11d0",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "https://github.com/albert-kepner/Week5_DL_CycleGAN/blob/master/AK_ModelArchitecture.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be84ef06",
   "metadata": {},
   "source": [
    "## Model Training and Development\n",
    "\n",
    "https://github.com/albert-kepner/Week5_DL_CycleGAN/blob/master/Model_Training_And_Development.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e1d80",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "We started with a copy of the Monet CycleGAN Tutorial notebook. We found that the initial batch size of 1 was not an efficent way to use TPUs for training. Also, initially the Monet and Photo images were zipped together without repetition, which means that the training epoch length was limited by the smaller data set. This means that only the first 300 photo images were used in each epoch of training.\n",
    "\n",
    "With changes to repeat the data set, we ensured that all the photos were included in the training. Increasing the batch size to 32 allowed us to do significantly more training within the available time. We did a somewhat ad hoc search to try to find the best amount of training to improve the Kaggle score. Our best result was a score of 37.37401 with a training length of 15,000 batches of 32 image pairs per batch. But the score was quite variable due to the random nature of the image generation, so we don't know if this was an optimum training length.\n",
    "\n",
    "Plotting the generator and discriminator losses over time shows evidence that the Monet discriminator is able to memorize features of the real Monet images, due to having only 300 of these images. So a possible improvement would be to augment the images by differentiable transformations, as was suggested here: Public Kaggle Notebook DiffAugment is all you need https://www.kaggle.com/code/unfriendlyai/diffaugment-is-all-you-need/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3765417d",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Kaggle Competition: https://www.kaggle.com/competitions/gan-getting-started\n",
    "\n",
    "1. Kaggle Tutorial: Amy Jang Notebook: https://www.kaggle.com/code/amyjang/monet-cyclegan-tutorial/notebook\n",
    "\n",
    "1. Public Github Project: CycleGAN\n",
    "An implementation of CycleGan for learning an image-to-image translation without input-output pairs using Keras.\n",
    "https://github.com/EtokonE/CycleGAN-keras#cyclegan\n",
    "\n",
    "1. Public Kaggle Notebook by SARAVANA KUMAR: https://www.kaggle.com/code/victorsullivan/i-m-something-of-a-painter-myself/notebook\n",
    "\n",
    "1. EBook: Generative Adversarial Networks with Python by Jason Brownlee -- https://machinelearningmastery.com/generative_adversarial_networks/\n",
    "\n",
    "1. Keras Cyclegan website https://keras.io/examples/generative/cyclegan/\n",
    "\n",
    "1. Public Kaggle Notebook DiffAugment is all you need https://www.kaggle.com/code/unfriendlyai/diffaugment-is-all-you-need/notebook\n",
    "\n",
    "1. Differentiable Augmentation for Data-Efficient GAN Training https://arxiv.org/abs/2006.10738"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186de32e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
